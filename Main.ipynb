{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMfREWI7v4SE9sj2N+gu3AK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/karandomguy/Phishing-Email-Detection/blob/dev/Main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install patool"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hoa-UezaOAjH",
        "outputId": "5dc9f3bb-3b61-4db6-bec5-5995b554f3a9"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting patool\n",
            "  Downloading patool-1.15.0-py2.py3-none-any.whl (91 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/91.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━\u001b[0m \u001b[32m81.9/91.1 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.1/91.1 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: patool\n",
            "Successfully installed patool-1.15.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import patoolib as pl\n",
        "pl.extract_archive(\"phishing_url_model.zip\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "id": "yI8BM838O1Nn",
        "outputId": "22dc96c9-ba73-4154-cba0-40f0c1559ef6"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "patool: Extracting phishing_url_model.zip ...\n",
            "patool: running /usr/bin/7z x -o./Unpack_am5j_40d -- phishing_url_model.zip\n",
            "patool: ... phishing_url_model.zip extracted to `best_pipeline_url.pkl'.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'best_pipeline_url.pkl'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def check_url(text):\n",
        "    url_pattern = \"[-a-zA-Z0-9@:%._\\\\+~#=]{1,256}\\\\.[a-zA-Z0-9()]{1,6}\\\\b(?:[-a-zA-Z0-9()@:%_\\\\+.~#?&\\\\/=]*)\"\n",
        "    urls = re.findall(url_pattern, text)\n",
        "    return urls"
      ],
      "metadata": {
        "id": "A7Cvx7M4Lk6i"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from urllib.parse import urlparse\n",
        "\n",
        "\n",
        "# First Directory Length\n",
        "def fd_length(url):\n",
        "    urlpath = urlparse(url).path\n",
        "    try:\n",
        "        return len(urlpath.split('/')[1])\n",
        "    except:\n",
        "        return 0\n",
        "\n",
        "\n",
        "def digit_count(url):\n",
        "    digits = 0\n",
        "    for i in url:\n",
        "        if i.isnumeric():\n",
        "            digits = digits + 1\n",
        "    return digits\n",
        "\n",
        "\n",
        "def letter_count(url):\n",
        "    letters = 0\n",
        "    for i in url:\n",
        "        if i.isalpha():\n",
        "            letters = letters + 1\n",
        "    return letters\n",
        "\n",
        "\n",
        "def no_of_dir(url):\n",
        "    urldir = urlparse(url).path\n",
        "    return urldir.count('/')\n",
        "\n",
        "\n",
        "# Use of IP or not in domain\n",
        "def having_ip_address(url):\n",
        "    match = re.search(\n",
        "        # IPv4 in hexadecimal\n",
        "        '(([01]?\\\\d\\\\d?|2[0-4]\\\\d|25[0-5])\\\\.([01]?\\\\d\\\\d?|2[0-4]\\\\d|25[0-5])\\\\.([01]?\\\\d\\\\d?|2[0-4]\\\\d|25[0-5])\\\\.'\n",
        "        '([01]?\\\\d\\\\d?|2[0-4]\\\\d|25[0-5])\\\\/)|'  # IPv4\n",
        "        '((0x[0-9a-fA-F]{1,2})\\\\.(0x[0-9a-fA-F]{1,2})\\\\.(0x[0-9a-fA-F]{1,2})\\\\.(0x[0-9a-fA-F]{1,2})\\\\/)'\n",
        "        '(?:[a-fA-F0-9]{1,4}:){7}[a-fA-F0-9]{1,4}', url)  # Ipv6\n",
        "    if match:\n",
        "        # print match.group()\n",
        "        return -1\n",
        "    else:\n",
        "        # print 'No matching pattern found'\n",
        "        return 1\n",
        "\n",
        "\n",
        "\n",
        "def hostname_length(url):\n",
        "    return len(urlparse(url).netloc)\n",
        "\n",
        "def url_length(url):\n",
        "    return len(urlparse(url).path)\n",
        "\n",
        "\n",
        "# Gets all count features\n",
        "def get_counts(url):\n",
        "\n",
        "    count_features = []\n",
        "\n",
        "    i = url.count('-')\n",
        "    count_features.append(i)\n",
        "\n",
        "    i = url.count('@')\n",
        "    count_features.append(i)\n",
        "\n",
        "    i = url.count('?')\n",
        "    count_features.append(i)\n",
        "\n",
        "    i = url.count('%')\n",
        "    count_features.append(i)\n",
        "\n",
        "    i = url.count('.')\n",
        "    count_features.append(i)\n",
        "\n",
        "    i = url.count('=')\n",
        "    count_features.append(i)\n",
        "\n",
        "    i = url.count('http')\n",
        "    count_features.append(i)\n",
        "\n",
        "    i = url.count('https')\n",
        "    count_features.append(i)\n",
        "\n",
        "    i = url.count('www')\n",
        "    count_features.append(i)\n",
        "\n",
        "    return count_features\n",
        "\n"
      ],
      "metadata": {
        "id": "CM7eOR1NMvFV"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_features(url):\n",
        "    url_features = []\n",
        "\n",
        "    # hostname length\n",
        "    i = hostname_length(url)\n",
        "    url_features.append(i)\n",
        "\n",
        "    # path length\n",
        "    i = url_length(url)\n",
        "    url_features.append(i)\n",
        "\n",
        "    i = fd_length(url)\n",
        "    url_features.append(i)\n",
        "\n",
        "    i = get_counts(url)\n",
        "    url_features = url_features + i\n",
        "\n",
        "    i = digit_count(url)\n",
        "    url_features.append(i)\n",
        "\n",
        "    i = letter_count(url)\n",
        "    url_features.append(i)\n",
        "\n",
        "    i = no_of_dir(url)\n",
        "    url_features.append(i)\n",
        "\n",
        "    i = having_ip_address(url)\n",
        "    url_features.append(i)\n",
        "\n",
        "    return url_features\n",
        "\n"
      ],
      "metadata": {
        "id": "grpzPEnnQdCn"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "import pickle\n",
        "def get_prediction(url, model_path):\n",
        "    print(\"Loading the model...\")\n",
        "\n",
        "    with open(model_path, 'rb') as model_file:\n",
        "        model = pickle.load(model_file)\n",
        "\n",
        "    print(\"Extracting features from url...\")\n",
        "    url_features = extract_features(url)\n",
        "    print(url_features)\n",
        "\n",
        "    print(\"Making prediction...\")\n",
        "    prediction = model.predict([url_features])\n",
        "\n",
        "    i = prediction[0][0] * 100\n",
        "    i = round(i, 3)\n",
        "    print(\"There is\", i, \"% chance, the URL is malicious!\")\n",
        "\n",
        "    return i"
      ],
      "metadata": {
        "id": "iz1Y04OTRKjt"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QOI_IJmmRMkM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}